<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title></title>
  <meta name="description" content="Planning-Guided Diffusion Policy Learning for Generalizable Contact-Rich Bimanual Manipulation">
  <meta name="keywords" content="GLIDE">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:title" content="Planning-Guided Diffusion Policy Learning for Generalizable Contact-Rich Bimanual Manipulation">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="Planning-Guided Diffusion Policy Learning for Generalizable Contact-Rich Bimanual Manipulation">
  <meta property="og:image" content="https://glide-manip.github.io/static/images/method.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="1604" />
  <meta property="og:image:height" content="387" />
  <meta property="og:url" content="https://glide-manip.github.io/" />
  <meta property="og:description" content="Project page for Planning-Guided Diffusion Policy Learning for Generalizable Contact-Rich Bimanual Manipulation" />
  <meta name="twitter:title" content="Planning-Guided Diffusion Policy Learning for Generalizable Contact-Rich Bimanual Manipulation" />
  <meta name="twitter:description" content="Project page for Planning-Guided Diffusion Policy Learning for Generalizable Contact-Rich Bimanual Manipulation" />
  <meta name="twitter:image" content="https://glide-manip.github.io/static/images/method.png" />

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-K93WDFV2');</script>
  <!-- End Google Tag Manager -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-K93WDFV2"
  height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Planning-Guided Diffusion Policy Learning for
              Generalizable Contact-Rich Bimanual Manipulation</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://xuanlinli17.github.io/">Xuanlin Li</a><sup>1,2</sup>,</span>
              <span class="author-block">
                <a href="https://www.linkedin.com/in/tongzhao997/">Tong Zhao</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://rolandzhu.github.io/">Xinghao Zhu</a><sup>1</sup>,
              </span>
               <span class="author-block">
                <a href="https://www.robo.guru/">Jiuguang Wang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://pangtao.xyz/">Tao Pang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://kuanfang.github.io/">Kuan Fang</a><sup>1,3</sup>,
              </span>
            </div>


            <div class="is-size-5 publication-authors">
              <!-- <span class="author-block"><sup><font size="-0.4">*</sup>Equal contribution †Core contributors ‡Equal advising</font></span><br> -->
              <span class="author-block"><sup>1</sup>Boston Dynamics AI Institute,</span>
              <span class="author-block"><sup>2</sup>UC San Diego,</span>
              <span class="author-block"><sup>3</sup>Cornell University</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href=".pdf"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper (coming soon)</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <!-- <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=SIcPxapIgBI" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span> -->
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://glide-manip.github.io"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>
                <!-- CoLab Link. -->

              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve has-text-centered">
            <video poster="" id="steve video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media12.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media6.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media9.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media10.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media7.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media3.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media5.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media11.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media8.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media4.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media14.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp has-text-centered">
            <video poster="" id="chair-tp video" autoplay controls muted loop playsinline height="100%">
              <source src="static/videos/media13.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Contact-rich bimanual manipulation involves precise coordination of two arms to change the state of objects through strategically selected contacts and motions. Due to the inherent complexity of these tasks, acquiring sufficient demonstration data and training policies that generalize to unseen scenarios remain a largely unresolved challenge. Building on recent advances in planning through contacts, we introduce Generalizable Planning-Guided Diffusion Policy Learning (GLIDE), an approach that effectively learns to solve contact-rich bimanual manipulation tasks by leveraging model-based motion planners to generate demonstration data in high-fidelity physics simulation. Through efficient planning in randomized environments, our approach generates large-scale and high-quality synthetic motion trajectories for tasks involving diverse objects and transformations. We then train a task-conditioned diffusion policy via behavior cloning using these demonstrations. To tackle the sim-to-real gap, we propose a set of essential design options in feature extraction, task representation, action prediction, and data augmentation that enable learning robust prediction of smooth action sequences and generalization to unseen scenarios. Through experiments in both simulation and the real world, we demonstrate that our approach can enable a bimanual robotic system to effectively manipulate objects of diverse geometries, dimensions, and physical properties.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <video autoplay controls muted loop playsinline width="100%">
              <source src="static/images/GLIDE.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
      
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Approach</h2>
          <div class="content has-text-justified has-text-centered">
            <img src="static/images/method.png" />
            <p>
              We propose <strong>G</strong>eneralizable P<strong>L</strong>anning-Gu<strong>I</strong>ded <strong>D</strong>iffusion Policy L<strong>E</strong>arning (GLIDE). We specifically consider a tabletop environment where a bimanual robot reorients a target object to a pose in SE(2). The policy takes in visual observations (specifically uncolored point clouds), proprioceptive robot joint angles, and task conditioning vector (i.e., <em>delta</em> transformation between the current and the target object pose) as input.
            </p>
            <p>
              Overall, we adopt a sim-to-real approach. We generate large-scale demonstrations in randomized simulation environments by building on the very recent advances in efficient motion planning through contact. We then filter out unsuccessful planner trajectories and the suboptimal trajectories that take too long to reach the goal, resulting in set of high-quality synthetic demonstrations.
            </p>
            <p>
              Next, we train a goal-conditioned point cloud diffusion policy using these synthetic demonstrations via Behavior Cloning. We clip the input point cloud within robot's workspace and remove irrelevant background. We also introduce several essential design choices that significantly enhance our policy's ability to transfer to the real world and generalize to unseen scenarios: <strong>(1)</strong> We introduce a <em>Flying Point Augmentation</em> approach that adds large Gaussian noise to points with a small probability; <strong>(2)</strong> Our policy predicts <em>residual</em> robot joint actions rather than absolute joint actions; <strong>(3)</strong> During inference, we use a larger action sequence length than originally used in the diffusion policy and DP3.
            </p>
            <p> 
              To deploy our policy in the real-world, we would like to track the changes in object pose for arbitrary objects. We achieve this by using open-world detection (Grounding-Dino) and segmentation (EfficientViT-SAM) to segment out the target object in the first frame. We then select keypoints within the segmented mask and track these keypoints across subsequent frames, allowing us to calculate the delta transformation in object pose.
            </p>
            
          </div>
        </div>
      </div>
    </div>
  </section>

    <section class="section">
      <div class="container is-max-desktop">

        <div class="columns is-centered">


          <!-- Animation. -->
          <div class="columns is-centered">
            <div class="column is-full-width">
              <h2 class="title is-3">Experiments</h2>
              <div class="content has-text-justified">
                <p>
                  To create our demonstration dataset, we generated 2,000 rectangular box primitives in simulation with randomized dimensions, mass, and friction coefficients. We then utilized our motion planning pipeline to generate ~30k successful demonstrations (takes about 2 days on 96-core cpu machine). We finally filter out suboptimal trajectories, rebalance the data, sample ~10k trajectories, and use Behavior Cloning to train our point cloud diffusion policy.
                </p>
              </div>
              <h3 class="title is-4">In-Distribution Evaluation</h3>
              <div class="content has-text-justified">
                <p>
                  We perform evaluation on objects whose geometries, dimensions, and physical properties are within the distribution of training demonstration trajectories.
                </p>
              </div>
              <div class="columns is-vcentered interpolation-panel">
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media5.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media6.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media7.mp4" type="video/mp4">
                  </video>
                </div>
              </div>
              <div class="columns is-vcentered interpolation-panel">
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media14.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media8.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media2.mp4" type="video/mp4">
                  </video>
                </div>
              </div>
              <br>
              <h3 class="title is-4">Out-of-Distribution Evaluation</h3>
              <div class="content has-text-justified">
                <p>
                  We perform evaluation on challenging out-of-distribution scenarios, including objects with novel geometries and physical properties, along with external perturbations. While we train our policy exclusively on box primitives, it already achieves good out-of-distribution generalization performance. A promising future direction is to further diversifying training environments by incorporating objects from large-scale datasets like Objaverse.
                </p>
              </div>
              <div class="columns is-vcentered interpolation-panel">
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media9.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media10.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media11.mp4" type="video/mp4">
                  </video>
                </div>
              </div>
              <div class="columns is-vcentered interpolation-panel">
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media1.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media4.mp4" type="video/mp4">
                  </video>
                </div>
                <div class="column  has-text-centered">
                  <video autoplay controls muted loop playsinline height="100%">
                    <source src="static/videos/media13.mp4" type="video/mp4">
                  </video>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>


    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        TBD
        <!-- <pre><code> @article{li24simpler,
        title={Evaluating Real-World Robot Manipulation Policies in Simulation},
        author={Xuanlin Li and Kyle Hsu and Jiayuan Gu and Karl Pertsch and Oier Mees and Homer Rich Walke and Chuyuan Fu and Ishikaa Lunawat and Isabel Sieh and Sean Kirmani and Sergey Levine and Jiajun Wu and Chelsea Finn and Hao Su and Quan Vuong and Ted Xiao},
        journal = {arXiv preprint arXiv:2405.05941},
        year={2024},
        } </code></pre> -->
      </div>
    </section>


    <footer class="footer">
      <div class="container">
        <div class="content has-text-centered">
          <a class="icon-link" href="https://arxiv.org/pdf/2210.05714.pdf">
            <i class="fas fa-file-pdf"></i>
          </a>
          <a class="icon-link" href="" class="external-link" disabled>
            <i class="fab fa-github"></i>
          </a>
        </div>
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">
              <p> Website borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a> under a <a
                  href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0
                  International</a>
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

</body>

</html>
